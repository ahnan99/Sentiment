I am familiar with linux commands to process lists and count values. Adding the hadoop calls to pull the necessary inputs from the HDFS filesystem are also fairly straightforward. Improving the MapReduce WordCount algorithm could be done in several ways. I'm sure as the course goes on these improvements will become more obvious. The concepts of skew and the components of a Hadoop cluster are becoming more familiar. Each daemon has a specific role and those components must work together.
