Homework 3 has been exciting. I learned about skew, which occurs when certain reduce tasks lag behind others because of the different lengths of value lists for each key. I learned about data locality optimization, which is when hadoop prefers to run map tasks on either the same node as the data or a node near the data according to network topology testing. I did hands-on unit testing and local job running to understand how local testing can be used to see the results of incremental changes. I found that these tools should be used first before submitting a job for the full data set to the cluster. I summarized the key differences between testing mapreduce programs locally and running it on the cluster. Locally, input and output locations are on the local filesystem, print statements are through stdout, and jobs can only have one reduce task.