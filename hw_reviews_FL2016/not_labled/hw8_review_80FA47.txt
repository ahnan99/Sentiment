Homework 8 was really fun because I learned about various similarity measures including pearson correlation, cosine similarity, and Jaccarbi distance and similarity. I learned that pearson correlation is equivalent to normalizing cosine similarity with respect to the mean of the data. Pearson correlation is advantageous from a quality perspective because lower ratings turn into negative numbers and higher ratings are positive. I liked how this homework included both a theoretical / proof component as well as an application component in which we implemented a MapReduce program that found the top n-list. This is indeed a map reduce application of big data that I wanted to explore when I signed up for the course.