This lab was fun because I learned about various spark commands and how to perform big data analysis using Python and Scala. I learned how to create different types of tables and elements by using the textFile or whole file format. I learned about various functions such as map and mapFlat which can perform a function for all the elements in an RDD. I also learned about how persistence can be used to speed up multi-job operations by preserving the data in an in-memory cache that is made available across the entire cluster. Lastly, I learned about the variety of running modes including client mode, local mode, and cluster mode.